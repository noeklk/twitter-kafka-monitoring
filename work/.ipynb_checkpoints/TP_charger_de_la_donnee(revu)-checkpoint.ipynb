{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Chargement de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Lire de la donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Lecture brute\n",
    "\n",
    "Chargez le fichier ville_1.csv dans une variable nommée df.\n",
    "\n",
    "Vous pouvez afficher votre donnée en utilisant la méthode take() ou la methode collect() de l'objet pyspark DataFrame (attention appeler collect() sur un dataframe est déconseillé si vous avez du vrai big data).\n",
    "\n",
    "L'objet possède aussi un attribut appelé dtypes, appelez cet attribut pour obtenir la liste des colonnes et leur type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('_c1', 'string'),\n",
       " ('_c2', 'string'),\n",
       " ('_c3', 'string'),\n",
       " ('_c4', 'string'),\n",
       " ('_c5', 'string'),\n",
       " ('_c6', 'string'),\n",
       " ('_c7', 'string'),\n",
       " ('_c8', 'string'),\n",
       " ('_c9', 'string'),\n",
       " ('_c10', 'string'),\n",
       " ('_c11', 'string'),\n",
       " ('_c12', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/Villes/ville_1.csv\"\n",
    "df = spark.read.load(path, format=\"csv\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Lecture avec les entêtes\n",
    "\n",
    "Recharger le même fichier mais cette fois-ci utilisez l'option header pour rajouter les noms de colonnes à votre df.\n",
    "\n",
    "Appelez l'attribut dtypes et comparez la sortie avec celle de la lecture brute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('vitesse_a_pied', 'string'),\n",
       " ('vitesse_a_velo', 'string'),\n",
       " ('home', 'string'),\n",
       " ('travail', 'string'),\n",
       " ('sportif', 'string'),\n",
       " ('casseur', 'string'),\n",
       " ('statut', 'string'),\n",
       " ('salaire', 'string'),\n",
       " ('sexe', 'string'),\n",
       " ('age', 'string'),\n",
       " ('sportivite', 'string'),\n",
       " ('velo_perf_minimale', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df = spark.read.format('csv').options(header=True).load(path)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Lecture avec les types détectés automatiquement\n",
    "\n",
    "Recharger le fichier avec  l'option inferShema.\n",
    "\n",
    "L'option 'inferSchema' permet de transformer les colonnes en types plus précis : entier  / booléens / chaines de caractères... bien sûr spark trouve les types uniquement si le fichier d'origine permet de les trouver de manière simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('vitesse_a_pied', 'double'),\n",
       " ('vitesse_a_velo', 'double'),\n",
       " ('home', 'string'),\n",
       " ('travail', 'string'),\n",
       " ('sportif', 'boolean'),\n",
       " ('casseur', 'boolean'),\n",
       " ('statut', 'string'),\n",
       " ('salaire', 'double'),\n",
       " ('sexe', 'string'),\n",
       " ('age', 'int'),\n",
       " ('sportivite', 'double'),\n",
       " ('velo_perf_minimale', 'double')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format('csv').options(header=True, inferSchema=True).load(path)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=5251, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:26.60 lat:28.13)', travail='(lon:21.08 lat:14.11)', sportif=False, casseur=False, statut='reserviste', salaire=29800.610034665042, sexe='F', age=18, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=5252, vitesse_a_pied=0.14974625830876215, vitesse_a_velo=0.37436564577190534, home='(lon:0.26 lat:42.61)', travail='(lon:36.35 lat:33.28)', sportif=False, casseur=False, statut='professeur', salaire=23595.44383981423, sexe='F', age=28, sportivite=0.7487312915438107, velo_perf_minimale=0.4),\n",
       " Row(id=5253, vitesse_a_pied=0.6309711587089704, vitesse_a_velo=1.6825897565572543, home='(lon:3.34 lat:13.95)', travail='(lon:24.75 lat:48.15)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18530.14776280135, sexe='H', age=65, sportivite=2.103237195696568, velo_perf_minimale=0.4),\n",
       " Row(id=5254, vitesse_a_pied=0.04009596300649916, vitesse_a_velo=0.10692256801733109, home='(lon:19.54 lat:43.69)', travail='(lon:38.57 lat:42.65)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18997.60281005325, sexe='H', age=26, sportivite=0.13365321002166386, velo_perf_minimale=0.4),\n",
       " Row(id=5255, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:28.51 lat:41.70)', travail='(lon:17.67 lat:25.16)', sportif=False, casseur=False, statut='éboueur', salaire=23618.479750220806, sexe='F', age=50, sportivite=0.1, velo_perf_minimale=0.4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) L'attribut schema\n",
    "\n",
    "Il vous permet d'afficher le schéma de votre df, avec pour chaque colonne son nom, son type, et si elle accepte les valeurs nulles ou non. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,true),StructField(vitesse_a_pied,DoubleType,true),StructField(vitesse_a_velo,DoubleType,true),StructField(home,StringType,true),StructField(travail,StringType,true),StructField(sportif,BooleanType,true),StructField(casseur,BooleanType,true),StructField(statut,StringType,true),StructField(salaire,DoubleType,true),StructField(sexe,StringType,true),StructField(age,IntegerType,true),StructField(sportivite,DoubleType,true),StructField(velo_perf_minimale,DoubleType,true)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez aussi la méthode printSchema() qui permet d'afficher le shéma du df de manière plus lisible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Ecriture de la dataframe sur le disque\n",
    "\n",
    "Sauvegardez le df sous différents formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) choix du format : csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").save(\"./data/Villes/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) choix du format : parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"parquet\").save(\"./data/Villes/parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) choix du format : json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.save(\"./data/Villes/ville\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Lecture de différents formats\n",
    "\n",
    "Vous pouvez choisir de lire le df sous un format ou un autre en utilisant l'argument format dans la fonction spark.read.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-c4a746cc-eba4-4649-acaa-72e73e13b1a2-c000.json  _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "# le ! vous permet d'executer des commandes dans votre terminal depuis le notebook\n",
    "!ls ./data/Villes/ville/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = spark.read.load(\"./data/Villes/ville/\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.load(\"./data/Villes/parquet\", format=\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Calculer des résultats : les actions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Nombre de lignes : count\n",
    "\n",
    "Chargez les fichiers csv contenus dans le dossiers ./data/Cyclistes/ dans un df nommé cyclistes, puis comptez les lignes du dataframe obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclistes = spark.read.load(\"./data/Cyclistes/\", format=\"csv\", header=True, inferSchema=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=246, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:02:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:03:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:04:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:05:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4868396"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher le schéma de ce nouveau df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,true),StructField(timestamp,StringType,true),StructField(sur_velo,BooleanType,true),StructField(velo,StringType,true),StructField(vitesse,DoubleType,true),StructField(position,StringType,true),StructField(destination_finale,StringType,true)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez 10 lignes du df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=246, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:02:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:03:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:04:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:05:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Moyenne : agg + colonne + mean\n",
    "\n",
    "A l'aide de la méthode agg(), calculez la moyenne sur la colonne vitesse.\n",
    "\n",
    "Vous pouvez récuperer le résultat avec la méthode collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(vitesse)|\n",
      "+------------------+\n",
      "|0.5635749865179047|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cyclistes.agg({'vitesse': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Quantile approximatifs pour gagner du temps de calcul\n",
    "\n",
    "En statistiques et en théorie des probabilités, les quantiles sont les valeurs qui divisent un jeu de données en intervalles contenant le même nombre de données. Il y a donc un quantile de moins que le nombre de groupes créés. Ainsi les quartiles sont les trois quantiles qui divisent un ensemble de données en quatre groupes de taille égale.\n",
    "\n",
    "La méthode approxQuantile permet de laisser une tolérance a l'erreur ce qui réduit le temps de calul sur d'énormes jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_quantile(df, erreur_acceptee):\n",
    "    debut            = time.time()\n",
    "    colonne          = \"vitesse\"\n",
    "    quantiles_voulus = [0.25, 0.50, 0.75]\n",
    "    resultat         =  df.approxQuantile(colonne, quantiles_voulus , erreur_acceptee )\n",
    "    fin              = time.time()\n",
    "    delais           = fin -debut\n",
    "    print (\"delais =%.2f sec, quantiles = %s\"%(delais, resultat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =5.63 sec, quantiles = [0.12867630286773463, 0.43636692359214846, 0.8358087561374254]\n"
     ]
    }
   ],
   "source": [
    "calcul_quantile(cyclistes, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =5.88 sec, quantiles = [0.13351057325728508, 0.467745329783825, 0.8357066787865304]\n"
     ]
    }
   ],
   "source": [
    "calcul_quantile(cyclistes, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =18.88 sec, quantiles = [0.13922027425674244, 0.467745329783825, 0.8358087561374254]\n"
     ]
    }
   ],
   "source": [
    "calcul_quantile(cyclistes, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload de la dataframe villes\n",
    "\n",
    "Chargez le fichier villes dans un df nommé villes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes = spark.read.load(\"./data/Villes/\", format=\"csv\", header=True, inferSchema=\"True\")\n",
    "villes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=5251, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:26.60 lat:28.13)', travail='(lon:21.08 lat:14.11)', sportif=False, casseur=False, statut='reserviste', salaire=29800.610034665042, sexe='F', age=18, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=5252, vitesse_a_pied=0.14974625830876215, vitesse_a_velo=0.37436564577190534, home='(lon:0.26 lat:42.61)', travail='(lon:36.35 lat:33.28)', sportif=False, casseur=False, statut='professeur', salaire=23595.44383981423, sexe='F', age=28, sportivite=0.7487312915438107, velo_perf_minimale=0.4),\n",
       " Row(id=5253, vitesse_a_pied=0.6309711587089704, vitesse_a_velo=1.6825897565572543, home='(lon:3.34 lat:13.95)', travail='(lon:24.75 lat:48.15)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18530.14776280135, sexe='H', age=65, sportivite=2.103237195696568, velo_perf_minimale=0.4),\n",
       " Row(id=5254, vitesse_a_pied=0.04009596300649916, vitesse_a_velo=0.10692256801733109, home='(lon:19.54 lat:43.69)', travail='(lon:38.57 lat:42.65)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18997.60281005325, sexe='H', age=26, sportivite=0.13365321002166386, velo_perf_minimale=0.4),\n",
       " Row(id=5255, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:28.51 lat:41.70)', travail='(lon:17.67 lat:25.16)', sportif=False, casseur=False, statut='éboueur', salaire=23618.479750220806, sexe='F', age=50, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=5256, vitesse_a_pied=0.8655449921165502, vitesse_a_velo=2.308119978977467, home='(lon:44.85 lat:45.65)', travail='(lon:9.18 lat:11.05)', sportif=False, casseur=False, statut='employe', salaire=19082.30894283764, sexe='H', age=57, sportivite=2.885149973721834, velo_perf_minimale=0.4),\n",
       " Row(id=5257, vitesse_a_pied=0.5879992290928728, vitesse_a_velo=1.4699980727321822, home='(lon:42.06 lat:43.69)', travail='(lon:0.51 lat:24.89)', sportif=False, casseur=False, statut='reserviste', salaire=21782.945135729053, sexe='F', age=75, sportivite=2.9399961454643644, velo_perf_minimale=0.4),\n",
       " Row(id=5258, vitesse_a_pied=0.8306610123216782, vitesse_a_velo=2.215096032857809, home='(lon:24.87 lat:16.06)', travail='(lon:36.80 lat:48.41)', sportif=False, casseur=False, statut='cadre', salaire=41451.270468058414, sexe='H', age=74, sportivite=2.768870041072261, velo_perf_minimale=0.4),\n",
       " Row(id=5259, vitesse_a_pied=0.12542885835859416, vitesse_a_velo=0.3344769556229178, home='(lon:9.07 lat:17.28)', travail='(lon:4.80 lat:9.81)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=22025.17074872747, sexe='H', age=57, sportivite=0.4180961945286472, velo_perf_minimale=0.4),\n",
       " Row(id=5260, vitesse_a_pied=0.030000000000000006, vitesse_a_velo=0.08, home='(lon:37.12 lat:43.64)', travail='(lon:24.72 lat:13.53)', sportif=False, casseur=False, statut='reserviste', salaire=38211.06301426453, sexe='H', age=24, sportivite=0.1, velo_perf_minimale=0.4)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) corrélation\n",
    "\n",
    "En probabilités et en statistique, la corrélation entre plusieurs variables aléatoires ou statistiques est une notion de liaison qui contredit leur indépendance.\n",
    "\n",
    "Calculez la corrélation entre les colonnes age et vitesse_a_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.017835846281407743"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.corr('age','vitesse_a_velo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5) covariance\n",
    "\n",
    "La covariance entre deux variables aléatoires est un nombre permettant de quantifier leurs écarts conjoints par rapport à leurs espérances respectives. Elle s’utilise également pour deux séries de données numériques (écarts par rapport aux moyennes).\n",
    "La covariance est une extension de la notion de variance. La corrélation est une forme normalisée de la covariance.\n",
    "\n",
    "Calculez la covariance entre les colonnes age et vitesse_a_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4752524914308339"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.cov('age','vitesse_a_velo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6) sample\n",
    "\n",
    "La méthode sample() permet de tirer aléatoirement une fraction du dataframe.\n",
    "Stockez dans un nouveau dataframe nommée villes_1pct, une fraction egale à 1% du df. Comptez le nombre de lignes obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+------------------+------------------+\n",
      "|  id|     vitesse_a_pied|     vitesse_a_velo|                home|             travail|sportif|casseur|              statut|           salaire|sexe|age|        sportivite|velo_perf_minimale|\n",
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+------------------+------------------+\n",
      "|5351| 1.5912476998003124|    4.2433271994675|(lon:19.75 lat:33...|(lon:19.96 lat:2.67)|  false|  false|technicien_de_sur...|19470.490974662098|   H| 33| 5.304158999334375|               0.4|\n",
      "|5474| 1.0549993188453546| 2.6374982971133867|(lon:28.85 lat:5.61)|(lon:42.81 lat:44...|  false|  false|technicien_de_sur...| 23224.53630730813|   F| 80| 5.274996594226773|               0.4|\n",
      "|5505| 1.1134903901142348| 2.9693077069712928|(lon:33.90 lat:47...|(lon:37.79 lat:2.76)|  false|  false|               cadre|23236.745750522525|   H| 32| 3.711634633714116|               0.4|\n",
      "|5567|0.38130174011496065| 1.0168046403065616|(lon:11.37 lat:33...|(lon:19.87 lat:39...|  false|  false|             éboueur|17305.169136800963|   H| 61| 1.271005800383202|               0.4|\n",
      "|5625|  0.359861905824156|  0.959631748864416|(lon:9.11 lat:34.27)|(lon:38.37 lat:0.71)|  false|  false|             employe|28550.496571745203|   H| 71|  1.19953968608052|               0.4|\n",
      "|5935|0.26736737826697554| 0.7129796753786014|(lon:46.46 lat:3.42)|(lon:20.29 lat:10...|  false|  false|             éboueur| 29252.84952806354|   H| 74|0.8912245942232517|               0.4|\n",
      "|6011| 0.6953453209071592|  1.738363302267898|(lon:29.97 lat:7.52)|(lon:0.79 lat:19.68)|  false|  false|             employe| 20897.66653544601|   F| 41| 3.476726604535796|               0.4|\n",
      "|6108|   1.05503730340796| 2.8134328090878937|(lon:20.58 lat:30...|(lon:44.07 lat:39...|  false|  false|          professeur| 34033.59816764861|   H| 18|3.5167910113598673|               0.4|\n",
      "|6111| 1.4657256671918222| 3.9086017791781926|(lon:45.51 lat:42...|(lon:25.04 lat:1.17)|  false|  false|               cadre|32105.303377977812|   H| 75| 4.885752223972741|               0.4|\n",
      "|6153|0.16147867807602415|0.40369669519006035|(lon:0.72 lat:23.90)|(lon:26.76 lat:27...|  false|  false|             employe|26168.556136139545|   F| 23|0.8073933903801207|               0.4|\n",
      "|6160|  0.166112572169783|0.41528143042445753|(lon:3.26 lat:16.33)|(lon:48.25 lat:12...|  false|  false|               cadre|19774.286980162422|   F| 75|0.8305628608489151|               0.4|\n",
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes_1pct = villes.sample(True, fraction=0.01)\n",
    "villes_1pct.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de la méthode exceptAll(), compter le nombre de ligne dans ville en omettant la fraction contenu dans ville_1pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.exceptAll(villes_1pct).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7) filter \n",
    "\n",
    "La méthode filter() permet le df selon certaines valeurs dans les colonnes.\n",
    "\n",
    "Utilisez cette méthode pour récuperer seulement les lignes avec le sexe féminin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "|  id|     vitesse_a_pied|     vitesse_a_velo|                home|             travail|sportif|casseur|              statut|           salaire|sexe|age|         sportivite|velo_perf_minimale|\n",
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "|5251|               0.02|               0.05|(lon:26.60 lat:28...|(lon:21.08 lat:14...|  false|  false|          reserviste|29800.610034665042|   F| 18|                0.1|               0.4|\n",
      "|5252|0.14974625830876215|0.37436564577190534|(lon:0.26 lat:42.61)|(lon:36.35 lat:33...|  false|  false|          professeur| 23595.44383981423|   F| 28| 0.7487312915438107|               0.4|\n",
      "|5255|               0.02|               0.05|(lon:28.51 lat:41...|(lon:17.67 lat:25...|  false|  false|             éboueur|23618.479750220806|   F| 50|                0.1|               0.4|\n",
      "|5257| 0.5879992290928728| 1.4699980727321822|(lon:42.06 lat:43...|(lon:0.51 lat:24.89)|  false|  false|          reserviste|21782.945135729053|   F| 75| 2.9399961454643644|               0.4|\n",
      "|5262|               0.02|               0.05|(lon:43.40 lat:25...|(lon:1.76 lat:18.95)|  false|  false|             employe|18155.392787144123|   F| 81|                0.1|               0.4|\n",
      "|5264| 0.6272243144514219| 1.5680607861285547|(lon:14.36 lat:33...|(lon:38.49 lat:41...|  false|  false|             éboueur|17894.342734488273|   F| 50| 3.1361215722571094|               0.4|\n",
      "|5266| 0.3167145553844886| 0.7917863884612215|(lon:44.53 lat:46...|(lon:31.66 lat:26...|  false|  false|          professeur| 32340.37164134604|   F| 74|  1.583572776922443|               0.4|\n",
      "|5271| 1.0637049252038342| 2.6592623130095854|(lon:7.35 lat:15.97)|(lon:23.48 lat:16...|  false|  false|               cadre|40170.674584023254|   F| 44|  5.318524626019171|               0.4|\n",
      "|5273|               0.02|               0.05|(lon:43.99 lat:14...|(lon:0.71 lat:35.14)|  false|  false|               cadre|30516.740487109822|   F| 39|                0.1|               0.4|\n",
      "|5276|               0.02|               0.05|(lon:35.60 lat:24...| (lon:9.45 lat:2.69)|  false|  false|             éboueur|21737.026343329253|   F| 61|                0.1|               0.4|\n",
      "|5277|0.33500607931826865| 0.8375151982956716|(lon:8.24 lat:42.40)|(lon:48.64 lat:32...|  false|  false|             éboueur|25013.554133869537|   F| 39| 1.6750303965913431|               0.4|\n",
      "|5278| 0.5612935671493225| 1.4032339178733064|(lon:3.60 lat:46.81)|(lon:0.23 lat:12.28)|  false|  false|             employe| 18306.64291062094|   F| 50|  2.806467835746613|               0.4|\n",
      "|5282| 0.8083175494888819| 2.0207938737222046|(lon:25.86 lat:5.51)|(lon:8.71 lat:13.09)|  false|  false|technicien_de_sur...|18011.276236369988|   F| 19|  4.041587747444409|               0.4|\n",
      "|5283| 1.2832501378500005| 3.2081253446250018|(lon:46.08 lat:3.40)|(lon:27.09 lat:47...|  false|  false|          professeur|24156.157989107276|   F| 53|  6.416250689250003|               0.4|\n",
      "|5284| 1.0364869412773074| 2.5912173531932687|(lon:30.00 lat:45...|(lon:2.79 lat:41.57)|  false|  false|technicien_de_sur...|18739.963697232994|   F| 35| 5.1824347063865375|               0.4|\n",
      "|5287|0.39938204132234967| 0.9984551033058742|(lon:45.02 lat:36...|(lon:33.44 lat:19...|  false|  false|          professeur|17011.719150211684|   F| 60| 1.9969102066117483|               0.4|\n",
      "|5288|0.09886577398124681|0.24716443495311702|(lon:21.03 lat:37...|(lon:33.67 lat:15...|  false|  false|             éboueur| 26756.93457723109|   F| 28|0.49432886990623404|               0.4|\n",
      "|5290|0.44011923092468674| 1.1002980773117168|(lon:5.70 lat:24.77)|(lon:41.90 lat:37...|  false|  false|             éboueur| 19038.02354817647|   F| 84| 2.2005961546234336|               0.4|\n",
      "|5291| 0.4525302271634198| 1.1313255679085494|(lon:13.50 lat:11...|(lon:35.01 lat:32...|  false|  false|             employe|16135.720678961883|   F| 46|  2.262651135817099|               0.4|\n",
      "|5292|               0.02|               0.05| (lon:6.05 lat:1.69)|(lon:34.49 lat:47...|  false|  false|             éboueur|  25233.0748967296|   F| 66|                0.1|               0.4|\n",
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.filter(villes.sexe == 'F').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peux aussi filtrer le df avec la méthode where(). Filtrez le df de la même façon que precedemment en utilisant cette méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "|  id|     vitesse_a_pied|     vitesse_a_velo|                home|             travail|sportif|casseur|              statut|           salaire|sexe|age|         sportivite|velo_perf_minimale|\n",
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "|5251|               0.02|               0.05|(lon:26.60 lat:28...|(lon:21.08 lat:14...|  false|  false|          reserviste|29800.610034665042|   F| 18|                0.1|               0.4|\n",
      "|5252|0.14974625830876215|0.37436564577190534|(lon:0.26 lat:42.61)|(lon:36.35 lat:33...|  false|  false|          professeur| 23595.44383981423|   F| 28| 0.7487312915438107|               0.4|\n",
      "|5255|               0.02|               0.05|(lon:28.51 lat:41...|(lon:17.67 lat:25...|  false|  false|             éboueur|23618.479750220806|   F| 50|                0.1|               0.4|\n",
      "|5257| 0.5879992290928728| 1.4699980727321822|(lon:42.06 lat:43...|(lon:0.51 lat:24.89)|  false|  false|          reserviste|21782.945135729053|   F| 75| 2.9399961454643644|               0.4|\n",
      "|5262|               0.02|               0.05|(lon:43.40 lat:25...|(lon:1.76 lat:18.95)|  false|  false|             employe|18155.392787144123|   F| 81|                0.1|               0.4|\n",
      "|5264| 0.6272243144514219| 1.5680607861285547|(lon:14.36 lat:33...|(lon:38.49 lat:41...|  false|  false|             éboueur|17894.342734488273|   F| 50| 3.1361215722571094|               0.4|\n",
      "|5266| 0.3167145553844886| 0.7917863884612215|(lon:44.53 lat:46...|(lon:31.66 lat:26...|  false|  false|          professeur| 32340.37164134604|   F| 74|  1.583572776922443|               0.4|\n",
      "|5271| 1.0637049252038342| 2.6592623130095854|(lon:7.35 lat:15.97)|(lon:23.48 lat:16...|  false|  false|               cadre|40170.674584023254|   F| 44|  5.318524626019171|               0.4|\n",
      "|5273|               0.02|               0.05|(lon:43.99 lat:14...|(lon:0.71 lat:35.14)|  false|  false|               cadre|30516.740487109822|   F| 39|                0.1|               0.4|\n",
      "|5276|               0.02|               0.05|(lon:35.60 lat:24...| (lon:9.45 lat:2.69)|  false|  false|             éboueur|21737.026343329253|   F| 61|                0.1|               0.4|\n",
      "|5277|0.33500607931826865| 0.8375151982956716|(lon:8.24 lat:42.40)|(lon:48.64 lat:32...|  false|  false|             éboueur|25013.554133869537|   F| 39| 1.6750303965913431|               0.4|\n",
      "|5278| 0.5612935671493225| 1.4032339178733064|(lon:3.60 lat:46.81)|(lon:0.23 lat:12.28)|  false|  false|             employe| 18306.64291062094|   F| 50|  2.806467835746613|               0.4|\n",
      "|5282| 0.8083175494888819| 2.0207938737222046|(lon:25.86 lat:5.51)|(lon:8.71 lat:13.09)|  false|  false|technicien_de_sur...|18011.276236369988|   F| 19|  4.041587747444409|               0.4|\n",
      "|5283| 1.2832501378500005| 3.2081253446250018|(lon:46.08 lat:3.40)|(lon:27.09 lat:47...|  false|  false|          professeur|24156.157989107276|   F| 53|  6.416250689250003|               0.4|\n",
      "|5284| 1.0364869412773074| 2.5912173531932687|(lon:30.00 lat:45...|(lon:2.79 lat:41.57)|  false|  false|technicien_de_sur...|18739.963697232994|   F| 35| 5.1824347063865375|               0.4|\n",
      "|5287|0.39938204132234967| 0.9984551033058742|(lon:45.02 lat:36...|(lon:33.44 lat:19...|  false|  false|          professeur|17011.719150211684|   F| 60| 1.9969102066117483|               0.4|\n",
      "|5288|0.09886577398124681|0.24716443495311702|(lon:21.03 lat:37...|(lon:33.67 lat:15...|  false|  false|             éboueur| 26756.93457723109|   F| 28|0.49432886990623404|               0.4|\n",
      "|5290|0.44011923092468674| 1.1002980773117168|(lon:5.70 lat:24.77)|(lon:41.90 lat:37...|  false|  false|             éboueur| 19038.02354817647|   F| 84| 2.2005961546234336|               0.4|\n",
      "|5291| 0.4525302271634198| 1.1313255679085494|(lon:13.50 lat:11...|(lon:35.01 lat:32...|  false|  false|             employe|16135.720678961883|   F| 46|  2.262651135817099|               0.4|\n",
      "|5292|               0.02|               0.05| (lon:6.05 lat:1.69)|(lon:34.49 lat:47...|  false|  false|             éboueur|  25233.0748967296|   F| 66|                0.1|               0.4|\n",
      "+----+-------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.where(villes.sexe == 'F').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Transformer la données : les transformations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations : demandent à être suivi par un collect ou une action (count par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Obtenir des statistiques sur les colonnes numériques\n",
    "\n",
    "La méthode describe() permet de calculer les statistiques récapitulatives d'une ou plusieurs colonnes numériques dans un df. Si le nom des colonnes n'est pas spécifié, la méthode calculera des statistiques récapitulatives pour toutes les colonnes numériques présentes dans le df.\n",
    "\n",
    "Afficher les statistiques de la colonne age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|              1083|\n",
      "|   mean| 49.30655586334257|\n",
      "| stddev|20.009984186582763|\n",
      "|    min|                15|\n",
      "|    max|                84|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.describe(\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) groupby\n",
    "\n",
    "La méthode groupBy() suivie de la methode agg() permet de grouper le df selon les catgories d'une ou plusieurs colonnes pour faire des calculs sur ces catégories.\n",
    "\n",
    "Calculez la moyenne de la colonnes sportivité selon le sexe des personnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|sexe|  avg(sportivite)|\n",
      "+----+-----------------+\n",
      "|   F|2.201847229112897|\n",
      "|   H|2.161359149481709|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(villes.sexe).agg({'sportivite': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la moyenne de la colonne age et la valeur max de la colonne sportivité par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------------------+\n",
      "|sexe|  max(sportivite)|          avg(age)|\n",
      "+----+-----------------+------------------+\n",
      "|   F|8.683572706695392|49.847036328871894|\n",
      "|   H|8.663362507588833|48.801785714285714|\n",
      "+----+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(villes.sexe).agg({'age': 'avg', 'sportivite': 'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la moyenne des colonnes vitesse_a_pied et vitesse_a_velo par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+\n",
      "|sexe|avg(vitesse_a_velo)|avg(vitesse_a_pied)|\n",
      "+----+-------------------+-------------------+\n",
      "|   F| 1.1131501228739036|  0.445260049149563|\n",
      "|   H| 1.8020997668473537| 0.6757874125677557|\n",
      "+----+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(villes.sexe).agg({'vitesse_a_pied': 'avg', 'vitesse_a_velo': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) summary\n",
    "\n",
    "La méthode summary() permet des faire des calculs statistiques de base sur toutes les colonnes du df.\n",
    "\n",
    "Appliquez un count et un max sur toutes les colonnes du df et afficher les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+-----------------+--------------------+-------------------+-------+-----------------+----+----+-----------------+------------------+\n",
      "|summary|  id|    vitesse_a_pied|   vitesse_a_velo|                home|            travail| statut|          salaire|sexe| age|       sportivite|velo_perf_minimale|\n",
      "+-------+----+------------------+-----------------+--------------------+-------------------+-------+-----------------+----+----+-----------------+------------------+\n",
      "|  count|1083|              1083|             1083|                1083|               1083|   1083|             1083|1083|1083|             1083|              1083|\n",
      "|    max|6333|3.7766588011416977|10.07109013637786|(lon:9.99 lat:17.81)|(lon:9.90 lat:0.36)|éboueur|80017.45851327667|   H|  84|8.683572706695392| 4.596287556824109|\n",
      "+-------+----+------------------+-----------------+--------------------+-------------------+-------+-----------------+----+----+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.summary('count','max').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4) Union de dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajouter les colonnes les unes à côté des autres : join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.join(villes, on=\"id\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajouter les lignes les unes sous les autres : union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2166"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.unionByName(villes).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6) Concaténation de colonne : F.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as spark_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ici reprendre le df cyclistes.\n",
    "\n",
    "Utiliser les méthodes withColumn() et F.concat() pour ajouter une colonne au df qui contiendra la concatenation des valeurs des colonnes id et sur_velo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cycistes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ed17f1144e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/Cyclistes/*.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcyclistes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcycistes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cycistes' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"./data/Cyclistes/*.csv\" \n",
    "cyclistes = spark.read.format(\"csv\").option(\"header\", \"true\").load(path, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=246, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:02:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:03:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:04:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False'),\n",
       " Row(id=246, timestamp='2018-01-01 00:05:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=246, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', id_sur_velo='246false'),\n",
       " Row(id=246, timestamp='2018-01-01 00:02:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', id_sur_velo='246false'),\n",
       " Row(id=246, timestamp='2018-01-01 00:03:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', id_sur_velo='246false'),\n",
       " Row(id=246, timestamp='2018-01-01 00:04:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', id_sur_velo='246false'),\n",
       " Row(id=246, timestamp='2018-01-01 00:05:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', id_sur_velo='246false')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.withColumn('id_sur_velo', spark_func.concat(cyclistes.id, cyclistes.sur_velo)).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Fonctions udf \n",
    "Il est possible d'enregistrer des fonctions python que l'on écrit nous même pour les appliquer sur une colonne d'une dataframe, c'est ce qu'on appelle les udf, pour User Defined Functions.\n",
    "\n",
    "Voici une fonction qui prend en argument une colonne et calcule le carré des valeurs de cette colonne.\n",
    "Appliquez cette fonction sur la colonne salaire de votre df. Affichez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf(returnType = FloatType())\n",
    "def cube(colonne):\n",
    "    return colonne*colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+------------+\n",
      "|  id|      vitesse_a_pied|     vitesse_a_velo|                home|             travail|sportif|casseur|              statut|           salaire|sexe|age|         sportivite|velo_perf_minimale|cube_salaire|\n",
      "+----+--------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+------------+\n",
      "|5251|                0.02|               0.05|(lon:26.60 lat:28...|(lon:21.08 lat:14...|  false|  false|          reserviste|29800.610034665042|   F| 18|                0.1|               0.4| 8.8807635E8|\n",
      "|5252| 0.14974625830876215|0.37436564577190534|(lon:0.26 lat:42.61)|(lon:36.35 lat:33...|  false|  false|          professeur| 23595.44383981423|   F| 28| 0.7487312915438107|               0.4| 5.5674496E8|\n",
      "|5253|  0.6309711587089704| 1.6825897565572543|(lon:3.34 lat:13.95)|(lon:24.75 lat:48...|  false|  false|technicien_de_sur...| 18530.14776280135|   H| 65|  2.103237195696568|               0.4|3.43366368E8|\n",
      "|5254| 0.04009596300649916|0.10692256801733109|(lon:19.54 lat:43...|(lon:38.57 lat:42...|  false|  false|technicien_de_sur...| 18997.60281005325|   H| 26|0.13365321002166386|               0.4|3.60908928E8|\n",
      "|5255|                0.02|               0.05|(lon:28.51 lat:41...|(lon:17.67 lat:25...|  false|  false|             éboueur|23618.479750220806|   F| 50|                0.1|               0.4| 5.5783258E8|\n",
      "|5256|  0.8655449921165502|  2.308119978977467|(lon:44.85 lat:45...|(lon:9.18 lat:11.05)|  false|  false|             employe| 19082.30894283764|   H| 57|  2.885149973721834|               0.4|3.64134528E8|\n",
      "|5257|  0.5879992290928728| 1.4699980727321822|(lon:42.06 lat:43...|(lon:0.51 lat:24.89)|  false|  false|          reserviste|21782.945135729053|   F| 75| 2.9399961454643644|               0.4|4.74496704E8|\n",
      "|5258|  0.8306610123216782|  2.215096032857809|(lon:24.87 lat:16...|(lon:36.80 lat:48...|  false|  false|               cadre|41451.270468058414|   H| 74|  2.768870041072261|               0.4|1.71820787E9|\n",
      "|5259| 0.12542885835859416| 0.3344769556229178|(lon:9.07 lat:17.28)| (lon:4.80 lat:9.81)|  false|  false|technicien_de_sur...| 22025.17074872747|   H| 57| 0.4180961945286472|               0.4| 4.8510816E8|\n",
      "|5260|0.030000000000000006|               0.08|(lon:37.12 lat:43...|(lon:24.72 lat:13...|  false|  false|          reserviste| 38211.06301426453|   H| 24|                0.1|               0.4|1.46008538E9|\n",
      "|5261|0.030000000000000006|               0.08|(lon:24.33 lat:17...|(lon:38.39 lat:10...|  false|  false|               cadre|32384.038031466876|   H| 73|                0.1|               0.4|1.04872589E9|\n",
      "|5262|                0.02|               0.05|(lon:43.40 lat:25...|(lon:1.76 lat:18.95)|  false|  false|             employe|18155.392787144123|   F| 81|                0.1|               0.4|3.29618272E8|\n",
      "|5263|  1.4342769187788869| 3.8247384500770316|(lon:31.39 lat:18...|(lon:16.55 lat:6.41)|  false|  false|             employe| 34479.64091466565|   H| 41| 4.7809230625962895|               0.4| 1.1888457E9|\n",
      "|5264|  0.6272243144514219| 1.5680607861285547|(lon:14.36 lat:33...|(lon:38.49 lat:41...|  false|  false|             éboueur|17894.342734488273|   F| 50| 3.1361215722571094|               0.4|3.20207488E8|\n",
      "|5265|  0.5056944896192869|  1.348518638984765|(lon:0.69 lat:27.44)|(lon:6.55 lat:19.14)|  false|  false|          professeur|15272.646527406627|   H| 62| 1.6856482987309562|               0.4|2.33253728E8|\n",
      "|5266|  0.3167145553844886| 0.7917863884612215|(lon:44.53 lat:46...|(lon:31.66 lat:26...|  false|  false|          professeur| 32340.37164134604|   F| 74|  1.583572776922443|               0.4|1.04589965E9|\n",
      "|5267|  0.3358134613272747| 0.8955025635393993|(lon:1.01 lat:47.34)|(lon:8.75 lat:29.22)|  false|  false|               cadre|30332.817374659553|   H| 26|  1.119378204424249|               0.4| 9.2007981E8|\n",
      "|5268|0.030000000000000006|               0.08|(lon:10.91 lat:12...| (lon:4.44 lat:3.66)|  false|  false|technicien_de_sur...| 11069.70965021214|   H| 20|                0.1|               0.4|1.22538472E8|\n",
      "|5269|    0.94148024700412|  2.510613992010987|(lon:48.82 lat:1.19)|(lon:15.11 lat:0.28)|  false|  false|          professeur|32542.663936348865|   H| 16| 3.1382674900137335|               0.4|1.05902496E9|\n",
      "|5270|0.030000000000000006|               0.08|(lon:21.87 lat:33...|(lon:37.77 lat:14...|  false|  false|               cadre| 31264.86511628485|   H| 43|                0.1|               0.4| 9.7749178E8|\n",
      "+----+--------------------+-------------------+--------------------+--------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.withColumn('cube_salaire', cube(villes.salaire)).show()\n",
    "# eN because there are very long number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6)\tEtude de cas : analyse des fichiers de logs des cyclistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1)  Charger la donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4868396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/Cyclistes/*.csv\" \n",
    "cyclistes = spark.read.format(\"csv\").option(\"header\", \"true\").load(path, inferSchema=True)\n",
    "cyclistes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2) vérifier le nombre de cycles\n",
    "\n",
    "Comptez le nombre d'id uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.select('id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3) transformer les timestamp en date\n",
    "\n",
    "Voici une fonction qui permert de récuperer la date sous forme de chaîne de caractère dans la colonne timestamps pour la transformer en date exploitable en tant que telle.\n",
    "\n",
    "Créez une nouvelle colonne dans votre df stockant le résultat de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "@udf(returnType = TimestampType())\n",
    "def ts_to_date(timestamp):\n",
    "    from datetime import datetime\n",
    "    return datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=246, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', date=datetime.datetime(2018, 1, 1, 0, 1)),\n",
       " Row(id=246, timestamp='2018-01-01 00:02:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', date=datetime.datetime(2018, 1, 1, 0, 2)),\n",
       " Row(id=246, timestamp='2018-01-01 00:03:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', date=datetime.datetime(2018, 1, 1, 0, 3)),\n",
       " Row(id=246, timestamp='2018-01-01 00:04:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', date=datetime.datetime(2018, 1, 1, 0, 4)),\n",
       " Row(id=246, timestamp='2018-01-01 00:05:00', sur_velo=False, velo='False', vitesse=0.02, position='(lon:22.62 lat:9.63)', destination_finale='False', date=datetime.datetime(2018, 1, 1, 0, 5))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes_date = cyclistes.withColumn('date', ts_to_date(cyclistes.timestamp))\n",
    "cyclistes_date.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4) Durée des trajets par id.\n",
    "\n",
    "A partir d'ici, il s'agit de traiter votre donnée pour récupérer la durée de chaque trajet effectué par chaque id.\n",
    "\n",
    "1) trouvez les dates min/max par état de sur_velo, puis par id ET par état de sur_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o173.agg.\n: java.lang.ClassCastException: class java.util.ArrayList cannot be cast to class java.lang.String (java.util.ArrayList and java.lang.String are in module java.base of loader 'bootstrap')\n\tat org.apache.spark.sql.RelationalGroupedDataset.$anonfun$agg$2(RelationalGroupedDataset.scala:201)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n\tat org.apache.spark.sql.RelationalGroupedDataset.agg(RelationalGroupedDataset.scala:201)\n\tat org.apache.spark.sql.RelationalGroupedDataset.agg(RelationalGroupedDataset.scala:220)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2c6c848c1782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcyclistes_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyclistes_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msur_velo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exprs should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o173.agg.\n: java.lang.ClassCastException: class java.util.ArrayList cannot be cast to class java.lang.String (java.util.ArrayList and java.lang.String are in module java.base of loader 'bootstrap')\n\tat org.apache.spark.sql.RelationalGroupedDataset.$anonfun$agg$2(RelationalGroupedDataset.scala:201)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n\tat org.apache.spark.sql.RelationalGroupedDataset.agg(RelationalGroupedDataset.scala:201)\n\tat org.apache.spark.sql.RelationalGroupedDataset.agg(RelationalGroupedDataset.scala:220)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "cyclistes_date.groupBy(cyclistes_date.sur_velo).agg({'date': ['min', 'max']}).take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Le résultat n'est pas trés pertinent, il faudrait plutôt le début et la fin de chaque trajet par id. Pour cela, il faudrait détecter les changements d'états \"sur_vélo\".\n",
    "Utilisez la classe Window() et la fonction F.lag() pour créer une nouvelle colonne que vous appellerez changement, contenant un 0 si l'état précedent de sur_velo est le même et un 1 si l'état vient de changer (fonction changement() ci-dessous) pour chaque id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType = IntegerType())\n",
    "def changement(etat_actuel, etat_precedent):\n",
    "    \"\"\"\n",
    "    Détecte si les deux états sont différent.\n",
    "    \n",
    "    Parametres :\n",
    "        etat_actuel : valeur sur la ligne courante\n",
    "                      renvoyée par F.lag (0)\n",
    "        etat_precedent : valeur sur la ligne précédente\n",
    "                      renvoyée par F.lag(1)\n",
    "    Return: 0 s'ils sont égaux, 1 s'il y a une différence\n",
    "    \"\"\"\n",
    "    if etat_precedent == None:\n",
    "        return 0\n",
    "    if etat_precedent == etat_actuel:\n",
    "        return 0\n",
    "    if etat_actuel != etat_precedent:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Grâce à la fonction window appliquez la fonction somme() sur la colonne changement pour numeroter les trajets pour chaque id et stocker les résulats dans une nouvelle colonne appelée numero_de_trajet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType = IntegerType())\n",
    "def somme(indice_actuel, indice_precedent):\n",
    "    if indice_precedent == None:\n",
    "        return 0\n",
    "    return indice_actuel + indice_precedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Il suffit maintenant de repêter la première étape, c'est a dire récupérer la début et la fin de chaque trajet pour chaque id. Puis calculer la durée des trajets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Datavisualisation\n",
    "\n",
    "Convertissez votre dataframe pyspark en dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de la librairie seaborn, réalisez un graphique en barre montrant la durée de tout les trajets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire le même graphique mais cette fois-ci, faire en sorte qu'on puisse choisir un id et afficher seulement les trajets de cet id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez votre dataset trajets au format csv dans le dossier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
